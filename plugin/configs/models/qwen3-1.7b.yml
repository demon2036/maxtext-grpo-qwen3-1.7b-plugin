# Qwen3-1.7B model config (plugin-local)
#
# Source of truth: https://huggingface.co/Qwen/Qwen3-1.7B/resolve/main/config.json
# This file exists to let MaxText load a new `model_name=qwen3-1.7b` **without**
# modifying upstream `third_party/maxtext`.

base_emb_dim: 2048
base_num_query_heads: 16
base_num_kv_heads: 8
base_mlp_dim: 6144
base_num_decoder_layers: 28
head_dim: 128
mlp_activations: ["silu", "linear"] # SwiGLU
vocab_size: 151936

decoder_block: "qwen3"

normalization_layer_epsilon: 1.0e-6
rope_max_timescale: 1000000

use_qk_norm: True

logits_via_embedding: True
normalize_embedding_logits: False
enable_dropout: False

tokenizer_type: "huggingface"

